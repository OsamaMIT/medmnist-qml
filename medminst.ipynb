{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQDQgwKQyi/semd6l+S5oJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSZu4w2jwQ5e",
        "outputId": "cdd2f457-c030-46ce-962f-e8ffbf0dad58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.16.0)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.13.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.2.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.5.21)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install qiskit medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load bloodmnist from the python module 'medmnist' and load prepare the data for torch ml later\n",
        "\n",
        "import medmnist\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Download and load the dataset using MedMNIST's API\n",
        "# Specify download=True to download the dataset if it's not present\n",
        "DOWNLOAD = True\n",
        "\n",
        "# Define transformations for the dataset\n",
        "# Convert numpy arrays to PyTorch tensors and normalize\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BloodMNIST dataset for training\n",
        "train = medmnist.BreastMNIST(split='train', download=DOWNLOAD, transform=data_transform)\n",
        "\n",
        "# Load the BloodMNIST dataset for validation (or testing)\n",
        "# You can choose 'val' or 'test' depending on your need\n",
        "test = medmnist.BreastMNIST(split='test', download=DOWNLOAD, transform=data_transform)\n",
        "\n",
        "print(\"Training dataset loaded:\", train)\n",
        "print(\"Test dataset loaded:\", test)\n",
        "\n",
        "# You can now create PyTorch DataLoaders for batch processing\n",
        "# batch_size = 64\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# The datasets (train_dataset and test_dataset) are now ready for use with PyTorch models.\n",
        "# Each item in the dataset will be a tuple (image, label) where image is a PyTorch tensor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ifg5iFrYIST",
        "outputId": "4cdc5938-9ab7-42bf-83ee-6fd6c3d390c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset loaded: Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 546\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "Test dataset loaded: Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 156\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from qiskit import QuantumCircuit\n",
        "#ParameterVector was redudant\n",
        "from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "#To control the random trainable parameters during development:\n",
        "torch.manual_seed(42)\n",
        "\n",
        "#VQA Circuit\n",
        "n_qubits = 4\n",
        "#Params were redudant\n",
        "\n",
        "def create_vqa_circuit(input_data, weights):\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    shift = 0  # index into weights array\n",
        "\n",
        "    # 1) Triple data re‑uploading with CZ entanglement\n",
        "    for _ in range(3):\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(input_data[i % len(input_data)], i)\n",
        "        for i in range(n_qubits - 1):\n",
        "            qc.cz(i, i + 1)\n",
        "        qc.barrier()\n",
        "\n",
        "    # 2) Two variational layers: mixed-axis rotations + ring CNOTs\n",
        "    for _ in range(2):\n",
        "        # each layer has 2 rotations per qubit\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(weights[shift], i); shift += 1\n",
        "            qc.ry(weights[shift], i); shift += 1\n",
        "        # ring entanglement\n",
        "        for i in range(n_qubits):\n",
        "            qc.cx(i, (i + 1) % n_qubits)\n",
        "        qc.barrier()\n",
        "\n",
        "    # 3) Final fine‑tune layer: one Ry per qubit\n",
        "    for i in range(n_qubits):\n",
        "        qc.ry(weights[shift], i)\n",
        "        shift += 1\n",
        "\n",
        "    return qc\n",
        "\n",
        "\n",
        "#Qiskit StatevectorEstimator primitive\n",
        "estimator = StatevectorEstimator()\n",
        "#observables = [ SparsePauliOp(\"Z\" + \"I\" * (n_qubits-1)) ] #Single multi-qubit gate\n",
        "observables = [\n",
        "    SparsePauliOp(\"\".join(\"Z\" if j == i else \"I\" for j in range(n_qubits)))\n",
        "    for i in range(n_qubits)\n",
        "] #A weighted sum will be applied using trainable reeadout parameters\n",
        "\n",
        "#PyTorch Custom Autograd Function For VQA Layer\n",
        "class VQALayerFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input_tensor, weights):\n",
        "        input_vals = input_tensor.detach().numpy()\n",
        "        weight_vals = weights.detach().numpy()\n",
        "        ctx.save_for_backward(input_tensor, weights)\n",
        "\n",
        "        qc = create_vqa_circuit(input_vals, weight_vals)\n",
        "        job = estimator.run([(qc, observables)])\n",
        "        expval = job.result()[0].data.evs\n",
        "\n",
        "        return torch.tensor([expval], dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input_tensor, weights = ctx.saved_tensors\n",
        "        input_vals = input_tensor.detach().numpy()\n",
        "        weight_vals = weights.detach().numpy()\n",
        "        shift = np.pi / 2\n",
        "        grads = []\n",
        "\n",
        "        for i in range(len(weight_vals)): # Grad is calculated using parameter shift rule\n",
        "            #print(\"Make changes here\")\n",
        "            #w abbreviates weight_vals\n",
        "            w_plus, w_minus = weight_vals.copy(), weight_vals.copy()\n",
        "            w_plus[i]  += shift\n",
        "            w_minus[i] -= shift\n",
        "\n",
        "            circuit_plus  = create_vqa_circuit(input_vals, w_plus)\n",
        "            circuit_minus = create_vqa_circuit(input_vals, w_minus)\n",
        "\n",
        "            EV_plus  = estimator.run([(circuit_plus, observables)]).result()[0].data.evs[0]\n",
        "            EV_minus = estimator.run([(circuit_minus, observables)]).result()[0].data.evs[0]\n",
        "\n",
        "            grads.append( 0.5 * (EV_plus - EV_minus) )\n",
        "\n",
        "\n",
        "        grads_tensor = torch.tensor(grads, dtype=torch.float32)\n",
        "        return None, (grad_output.view(-1)[0] * grads_tensor).view(-1)\n",
        "\n",
        "#Quantum Layer as PyTorch Module\n",
        "class VQALayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(5 * n_qubits)) #trainable parameters for the circuit\n",
        "        self.best_weights = self.weights.detach().clone() #to capture the best weights during training\n",
        "        self.readout_w = nn.Parameter(torch.ones(n_qubits) / n_qubits) #trainable parameters for the a weighted Pauli sum observable\n",
        "\n",
        "    def forward(self, x):\n",
        "        #run quantum circuit on each sample\n",
        "        expvals = torch.stack([\n",
        "            VQALayerFunction.apply(x[i], self.weights)\n",
        "            for i in range(x.size(0))\n",
        "        ], dim=0).squeeze(1)  #tensor shape [batch, n_qubits]\n",
        "\n",
        "        return expvals #Returns expectation for each qubit\n",
        "\n",
        "        #return torch.stack([VQALayerFunction.apply(x[i], self.weights) for i in range(x.size(0))]).view(-1, 1)\n",
        "\n",
        "#Full Hybrid Model\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.classical = nn.Linear(train[0][0].numel(), n_qubits)\n",
        "        self.quantum = VQALayer()\n",
        "        self.readout_w = nn.Parameter(torch.ones(n_qubits))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classical(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.quantum(x)\n",
        "        x = (x * self.readout_w).sum(dim=1, keepdim=True)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "model = HybridModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "#Training Loop\n",
        "batch_size = 64\n",
        "train_loader  = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "best_rocauc = 0\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    #Iterate over batches\n",
        "    for Xb, Yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(Xb)\n",
        "        loss = loss_fn(preds, Yb.float())\n",
        "        loss.backward()\n",
        "\n",
        "        #Print gradient norms for all parameters\n",
        "        # for name, param in model.named_parameters():\n",
        "        #     if param.grad is not None:\n",
        "        #         print(f\"{name} grad_norm = {param.grad.norm():.4f}\")\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # compute epoch-level metrics via the DataLoader\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xb, Yb in train_loader:\n",
        "            preds = model(Xb).view(-1)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(Yb.view(-1).cpu())\n",
        "\n",
        "    y_scores = torch.cat(all_preds).numpy()\n",
        "    y_true   = torch.cat(all_labels).numpy().astype(int)\n",
        "    acc_full = ( (y_scores > 0.5) == y_true ).mean()\n",
        "    rocauc   = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f} | Accuracy: {acc_full*100:.2f}% | ROC AUC: {rocauc:.4f}\")\n",
        "\n",
        "    #Record best params\n",
        "    rocauc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    if rocauc > best_rocauc:\n",
        "        model.quantum.best_weights = model.quantum.weights.detach().clone()\n",
        "        best_rocauc = rocauc\n",
        "\n",
        "    if epoch == epochs-1:\n",
        "        print(f\"Best weights: {model.quantum.best_weights}\\n Best ROCAUC: {best_rocauc}\")\n",
        "\n",
        "    model.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNL7M0DgWg20",
        "outputId": "581b825e-84d9-4be1-cf7b-da0be9dcd52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Avg Loss: 0.7541 | Accuracy: 42.67% | ROC AUC: 0.5944\n",
            "Epoch 2 | Avg Loss: 0.6889 | Accuracy: 67.03% | ROC AUC: 0.5666\n",
            "Epoch 3 | Avg Loss: 0.6508 | Accuracy: 71.79% | ROC AUC: 0.5486\n",
            "Epoch 4 | Avg Loss: 0.6312 | Accuracy: 72.16% | ROC AUC: 0.5520\n",
            "Epoch 5 | Avg Loss: 0.6121 | Accuracy: 72.53% | ROC AUC: 0.5653\n",
            "Epoch 6 | Avg Loss: 0.5993 | Accuracy: 72.53% | ROC AUC: 0.5758\n",
            "Epoch 7 | Avg Loss: 0.5902 | Accuracy: 72.71% | ROC AUC: 0.5852\n",
            "Epoch 8 | Avg Loss: 0.5810 | Accuracy: 72.89% | ROC AUC: 0.5966\n",
            "Epoch 9 | Avg Loss: 0.5840 | Accuracy: 72.89% | ROC AUC: 0.5963\n",
            "Epoch 10 | Avg Loss: 0.5678 | Accuracy: 72.89% | ROC AUC: 0.6111\n",
            "Best weights: tensor([-0.0115,  1.0955, -0.1100, -0.1695,  0.9276, -0.4935,  0.7547,  1.4807,\n",
            "         1.0255,  2.1790, -0.5769, -0.0102, -1.4060,  2.1734,  0.3246, -0.9725,\n",
            "        -0.1712,  0.2488, -0.0217,  0.2170])\n",
            " Best ROCAUC: 0.6110855369716808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement Testing Loop:\n",
        "model.quantum.weights.data.copy_(model.quantum.best_weights.detach().clone())\n",
        "\n",
        "test_loader  = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "all_scores, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for Xb, Yb in test_loader:\n",
        "        probs = model(Xb).view(-1).cpu().numpy()\n",
        "        all_scores.append(probs)\n",
        "        all_labels.append(Yb.view(-1).cpu().numpy())\n",
        "y_scores = np.concatenate(all_scores)\n",
        "y_true   = np.concatenate(all_labels).astype(int)\n",
        "\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "best_t, best_acc = 0.5, 0.0\n",
        "for t in thresholds:\n",
        "    preds = (y_scores >= t).astype(int)\n",
        "    acc   = (preds == y_true).mean()\n",
        "    if acc > best_acc:\n",
        "        best_acc, best_t = acc, t\n",
        "print(f\"Optimal threshold = {best_t:.2f}, accuracy = {best_acc:.4f}\\n\")\n",
        "\n",
        "preds_best = (y_scores >= best_t).astype(int)\n",
        "\n",
        "acc    = accuracy_score(y_true, preds_best)\n",
        "prec   = precision_score(y_true, preds_best)\n",
        "rec    = recall_score(y_true, preds_best)\n",
        "f1     = f1_score(y_true, preds_best)\n",
        "rocauc = roc_auc_score(y_true, y_scores) # Use y_scores for ROC AUC\n",
        "cm     = confusion_matrix(y_true, preds_best)\n",
        "\n",
        "# Print results\n",
        "print(\"--- Test Set Metrics ---\")\n",
        "print(f\"Test Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision:      {prec:.4f}\")\n",
        "print(f\"Recall:         {rec:.4f}\")\n",
        "print(f\"F1-Score:       {f1:.4f}\")\n",
        "print(f\"ROC AUC:        {rocauc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpPZjeyZhXD-",
        "outputId": "25a6d80c-64e2-424e-c53f-3b4caa5d9958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal threshold = 0.57, accuracy = 0.7372\n",
            "\n",
            "--- Test Set Metrics ---\n",
            "Test Accuracy:  0.7372\n",
            "Precision:      0.7355\n",
            "Recall:         1.0000\n",
            "F1-Score:       0.8476\n",
            "ROC AUC:        0.6368\n",
            "Confusion Matrix:\n",
            "[[  1  41]\n",
            " [  0 114]]\n"
          ]
        }
      ]
    }
  ]
}